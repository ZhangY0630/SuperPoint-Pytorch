{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8bff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from copy import deepcopy\n",
    "from utils.params import dict_update\n",
    "from dataset.utils.homographic_augmentation import homographic_aug_pipline\n",
    "from dataset.utils.photometric_augmentation import PhotoAugmentor\n",
    "from utils.keypoint_op import compute_keypoint_map\n",
    "from dataset.utils.photometric_augmentation import *\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from solver.sfm_loss import *\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d43a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, config, is_train, device='cpu'):\n",
    "\n",
    "        super(SelfDataset, self).__init__()\n",
    "        self.device = device\n",
    "        self.is_train = is_train\n",
    "        self.resize = tuple(config['resize'])\n",
    "        self.photo_augmentor = PhotoAugmentor(config['augmentation']['photometric'])\n",
    "        self.config = config\n",
    "        if self.is_train:\n",
    "            self.samples = self._init_data(config['image_train_path'], config['label_train_path'], config['pairs_train_path'])\n",
    "        else:\n",
    "            self.samples = self._init_data(config['image_test_path'], config['label_test_path'], config['pairs_test_path'])\n",
    "\n",
    "\n",
    "    def _init_data(self, image_path, label_path=None, pair_path=None):\n",
    "        ##\n",
    "        if not isinstance(image_path,list):\n",
    "            image_paths, label_paths, pair_paths = [image_path,], [label_path,], [pair_path,]\n",
    "        else:\n",
    "            image_paths, label_paths, pair_paths = image_path, label_path, pair_path\n",
    "\n",
    "        image_types = ['jpg','jpeg','bmp','png']\n",
    "        samples = []\n",
    "        for im_path, lb_path, pair_path in zip(image_paths, label_paths, pair_paths):\n",
    "            pairs = np.load(os.path.join(pair_path, 'pairs.npy'), allow_pickle=True)\n",
    "            pairs = pairs.item()\n",
    "            templist = ['1377155868.png']\n",
    "            for key in templist:\n",
    "                filename = key.split(\".\")[0]\n",
    "                temp_im = os.path.join(im_path, key)\n",
    "                if lb_path is not None:\n",
    "                    temp_lb = os.path.join(lb_path, filename+'.npy')\n",
    "                else:\n",
    "                    temp_lb = None\n",
    "                for i in range(len(pairs[key]['pairs'])):\n",
    "                    pair = pairs[key]['pairs'][i]\n",
    "                    filename = pair.split(\".\")[0]\n",
    "                    covisibility = pairs[key]['covisibility'][i]\n",
    "                    index = pairs[key]['index'][i]\n",
    "                    temp_im1 = os.path.join(im_path, pair)\n",
    "                    if lb_path is not None:\n",
    "                        temp_lb1 = os.path.join(lb_path, filename+'.npy')\n",
    "                    else:\n",
    "                        temp_lb1 = None\n",
    "                    samples.append({'image':temp_im, 'label':temp_lb, 'image1':temp_im1, 'label1': temp_lb1, 'index': index, 'covisibility': covisibility})\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''load raw data'''\n",
    "        \n",
    "        data_path = self.samples[idx]\n",
    "        \n",
    "         # load images\n",
    "        img = cv2.imread(data_path['image'], 0)#Gray image\n",
    "        img = cv2.resize(img, self.resize[::-1])\n",
    "        img_tensor = torch.as_tensor(img.copy(), dtype=torch.float, device=self.device)\n",
    "        img1 = cv2.imread(data_path['image1'], 0)#Gray image\n",
    "        img1 = cv2.resize(img1, self.resize[::-1])\n",
    "        img_tensor1 = torch.as_tensor(img1.copy(), dtype=torch.float, device=self.device)\n",
    "\n",
    "        pts = None if data_path['label'] is None else np.load(data_path['label'])[:, [1,0,2]]\n",
    "        pts1 = None if data_path['label1'] is None else np.load(data_path['label1'])[:, [1,0,2]]\n",
    "        pts[:, 0] = (pts[:, 0]+0.5)/1200*self.resize[0]\n",
    "        pts[:, 1] = (pts[:, 1]+0.5)/1920*self.resize[1]\n",
    "        pts1[:, 0] = (pts1[:, 0]+0.5)/1200*self.resize[0]\n",
    "        pts1[:, 1] = (pts1[:, 1]+0.5)/1920*self.resize[1]\n",
    "        \n",
    "        kpts_tensor = None if pts is None else torch.as_tensor(pts, device=self.device)\n",
    "        kpts_tensor1 = None if pts1 is None else torch.as_tensor(pts1, device=self.device)\n",
    "        \n",
    "        # compute maps\n",
    "        kpts_map = None if pts is None else compute_keypoint_map(kpts_tensor, img.shape, device=self.device, id_included=True)\n",
    "        kpts_map1 = None if pts1 is None else compute_keypoint_map(kpts_tensor1, img1.shape, device=self.device, id_included=True)\n",
    "        valid_mask = torch.ones(img.shape, device=self.device)\n",
    "        valid_mask1 = torch.ones(img1.shape, device=self.device)\n",
    "        \n",
    "\n",
    "        data = {    'image':{'raw':{'img': img_tensor,\n",
    "                                    'kpts': kpts_tensor,\n",
    "                                    'kpts_map':kpts_map,\n",
    "                                    'mask': valid_mask},\n",
    "                            'warp':{'img': None,\n",
    "                                    'kpts': None,\n",
    "                                    'kpts_map':None,\n",
    "                                    'mask': None},\n",
    "                            'homo': torch.eye(3,device=self.device)},\n",
    "                    'image1':{'raw':{'img': img_tensor1,\n",
    "                                    'kpts': kpts_tensor1,\n",
    "                                    'kpts_map':kpts_map1,\n",
    "                                    'mask': valid_mask1},\n",
    "                            'warp':{'img': None,\n",
    "                                    'kpts': None,\n",
    "                                    'kpts_map':None,\n",
    "                                    'mask': None},\n",
    "                            'homo': torch.eye(3,device=self.device)}, \n",
    "                    'pairs': None      \n",
    "                }\n",
    "        \n",
    "        # compute warpings\n",
    "        data['image']['warp'] = deepcopy(data['image']['raw'])\n",
    "        data['image1']['warp'] = deepcopy(data['image1']['raw'])\n",
    "        \n",
    "        if self.is_train:\n",
    "            photo_enable = self.config['augmentation']['photometric']['train_enable']\n",
    "            homo_enable = self.config['augmentation']['homographic']['train_enable']\n",
    "        else:\n",
    "            photo_enable = self.config['augmentation']['photometric']['test_enable']\n",
    "            homo_enable = self.config['augmentation']['homographic']['test_enable']\n",
    "\n",
    "        if homo_enable and data['image']['raw']['kpts'] is not None and data['image1']['raw']['kpts'] is not None:#homographic augmentation\n",
    "            data_homo = homographic_aug_pipline(data['image']['warp']['img'],\n",
    "                                                data['image']['warp']['kpts'],\n",
    "                                                self.config['augmentation']['homographic'],\n",
    "                                                device=self.device, id_included=True)\n",
    "            data_homo1 = homographic_aug_pipline(data['image1']['warp']['img'],\n",
    "                                                data['image1']['warp']['kpts'],\n",
    "                                                self.config['augmentation']['homographic'],\n",
    "                                                device=self.device, id_included=True)\n",
    "            data['image'].update(data_homo)\n",
    "            data['image1'].update(data_homo1)\n",
    "            \n",
    "        if photo_enable:\n",
    "            photo_img = data['image']['warp']['img'].cpu().numpy().round().astype(np.uint8)\n",
    "            photo_img = self.photo_augmentor(photo_img)\n",
    "            data['image']['warp']['img'] = torch.as_tensor(photo_img, dtype=torch.float,device=self.device)\n",
    "            photo_img1 = data['image1']['warp']['img'].cpu().numpy().round().astype(np.uint8)\n",
    "            photo_img1 = self.photo_augmentor(photo_img1)\n",
    "            data['image1']['warp']['img'] = torch.as_tensor(photo_img1, dtype=torch.float,device=self.device)\n",
    "        \n",
    "        # compute new pairs and index\n",
    "        pairs_dict = dict.fromkeys(data_path['covisibility'], -1)\n",
    "        index_dict = dict.fromkeys(data_path['index'], -1)\n",
    "        pairs_list = data_path['covisibility']\n",
    "        index_list = data_path['index']\n",
    "        pairs = []\n",
    "        index = []\n",
    "        \n",
    "        for i, x in enumerate(data['image']['warp']['kpts']):\n",
    "            if int(x[2]) in index_dict:\n",
    "                index_dict[int(x[2])] = i\n",
    "        for i, x in enumerate(data['image1']['warp']['kpts']):\n",
    "            if int(x[2]) in pairs_dict:\n",
    "                pairs_dict[int(x[2])] = i\n",
    "        \n",
    "        for i in range(len(pairs_list)):\n",
    "            if pairs_dict[pairs_list[i]] != -1 and index_dict[index_list[i]] != -1:\n",
    "                pairs.append([index_dict[index_list[i]], pairs_dict[pairs_list[i]]])\n",
    "        \n",
    "        data['pairs'] = torch.as_tensor(np.array(pairs).astype(np.int), device=self.device)\n",
    "        \n",
    "        # remove the old index from points & normalize images\n",
    "        for image_flag in ['image','image1']:\n",
    "            for warp_flag in ['raw','warp']:\n",
    "                data[image_flag][warp_flag]['kpts'] = data[image_flag][warp_flag]['kpts'][:,:2].int()\n",
    "                data[image_flag][warp_flag]['img'] = data[image_flag][warp_flag]['img']/255.\n",
    "        \n",
    "        return data\n",
    "    \n",
    "\n",
    "    def batch_collator(self, samples):\n",
    "        \"\"\"\n",
    "        :param samples:a list, each element is a dict with keys\n",
    "        like `img`, `img_name`, `kpts`, `kpts_map`,\n",
    "        `valid_mask`, `homography`...\n",
    "        img:H*W, kpts:N*2, kpts_map:HW, valid_mask:HW, homography:HW\n",
    "        :return:\n",
    "        \"\"\"\n",
    "#         sub_data={  'raw':{ 'img':      [],\n",
    "#                             'kpts':     [],\n",
    "#                             'kpts_map': [],\n",
    "#                             'mask':     []},\n",
    "#                     'warp':{'img':      [],\n",
    "#                             'kpts':     [],\n",
    "#                             'kpts_map': [],\n",
    "#                             'mask':     []},\n",
    "#                     'homo':             []}\n",
    "        sub_data={  'raw':{ 'img':      [],\n",
    "                            'kpts':     [],\n",
    "                            'kpts_map': []},\n",
    "                    'warp':{'img':      [],\n",
    "                            'kpts':     [],\n",
    "                            'kpts_map': []}}\n",
    "        batch = {'image':deepcopy(sub_data), 'image1':deepcopy(sub_data), 'masks': [], 'pairs': []}\n",
    "        for s in samples:\n",
    "            batch['pairs'].append(s['pairs'])\n",
    "            batch['image']['raw']['img'].append(s['image']['raw']['img'].unsqueeze(dim=0))\n",
    "            batch['image']['raw']['kpts'].append(s['image']['raw']['kpts'])\n",
    "            batch['image']['raw']['kpts_map'].append(s['image']['raw']['kpts_map'])\n",
    "#             batch['image']['raw']['mask'].append(s['image']['raw']['mask'])\n",
    "            batch['image']['warp']['img'].append(s['image']['warp']['img'].unsqueeze(dim=0))\n",
    "            batch['image']['warp']['kpts'].append(s['image']['warp']['kpts'])\n",
    "            batch['image']['warp']['kpts_map'].append(s['image']['warp']['kpts_map'])\n",
    "#             batch['image']['warp']['mask'].append(s['image']['warp']['mask'])\n",
    "#             batch['image']['homo'].append(s['image']['homo'])\n",
    "            batch['image1']['raw']['img'].append(s['image1']['raw']['img'].unsqueeze(dim=0))\n",
    "            batch['image1']['raw']['kpts'].append(s['image1']['raw']['kpts'])\n",
    "            batch['image1']['raw']['kpts_map'].append(s['image1']['raw']['kpts_map'])\n",
    "#             batch['image1']['raw']['mask'].append(s['image1']['raw']['mask'])\n",
    "            batch['image1']['warp']['img'].append(s['image1']['warp']['img'].unsqueeze(dim=0))\n",
    "            batch['image1']['warp']['kpts'].append(s['image1']['warp']['kpts'])\n",
    "            batch['image1']['warp']['kpts_map'].append(s['image1']['warp']['kpts_map'])\n",
    "            batch['masks'].append(torch.stack((s['image']['warp']['mask'], s['image']['warp']['mask']), dim=0))\n",
    "#             batch['image1']['warp']['mask'].append(s['image1']['warp']['mask'])\n",
    "#             batch['image1']['homo'].append(s['image1']['homo'])\n",
    "        batch['masks'] = torch.stack(batch['masks'])\n",
    "        for k0 in ('image','image1'):\n",
    "#             batch[k0]['homo'] = torch.stack(batch[k0]['homo'])\n",
    "            for k1 in ('raw','warp'):\n",
    "                for k2 in ('img', 'kpts_map'):\n",
    "                    batch[k0][k1][k2] = torch.stack(batch[k0][k1][k2])\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c321b2c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d0301c8b4e31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselfdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselfdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_collator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sp/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sp/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sp/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sp/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5008e1f98457>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_flag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'image1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mwarp_flag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'raw'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'warp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_flag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwarp_flag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kpts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_flag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwarp_flag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kpts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_flag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwarp_flag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_flag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwarp_flag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    with open('/Users/zhouchang/Documents/GitHub/SuperPoint-Pytorch/config/superpoint_train.yaml','r') as fin:\n",
    "        config = yaml.safe_load(fin)\n",
    "\n",
    "    selfdata = SelfDataset(config['data'],True)\n",
    "    cdataloader = DataLoader(selfdata,collate_fn=selfdata.batch_collator,batch_size=1,shuffle=True)\n",
    "\n",
    "    for i,d in enumerate(cdataloader):\n",
    "        if i>=5:\n",
    "            break\n",
    "        print(i, d)\n",
    "        img = (d['image']['raw']['img']*255).cpu().numpy().squeeze().astype(np.int).astype(np.uint8)\n",
    "        img = cv2.merge([img, img, img])\n",
    "        img_warp = (d['image']['warp']['img']*255).cpu().numpy().squeeze().astype(np.int).astype(np.uint8)\n",
    "        img_warp = cv2.merge([img_warp, img_warp, img_warp])\n",
    "        img1 = (d['image1']['raw']['img']*255).cpu().numpy().squeeze().astype(np.int).astype(np.uint8)\n",
    "        img1 = cv2.merge([img1, img1, img1])\n",
    "        img_warp1 = (d['image1']['warp']['img']*255).cpu().numpy().squeeze().astype(np.int).astype(np.uint8)\n",
    "        img_warp1 = cv2.merge([img_warp1, img_warp1, img_warp1])\n",
    "        kpts = np.where(d['image']['raw']['kpts_map'].squeeze().cpu().numpy())\n",
    "        kpts = np.vstack(kpts).T\n",
    "        kpts = np.round(kpts).astype(np.int)\n",
    "        for kp in kpts:\n",
    "            cv2.circle(img, (kp[1], kp[0]), radius=1, color=(0,255,0))\n",
    "        kpts = np.where(d['image']['warp']['kpts_map'].squeeze().cpu().numpy())\n",
    "        kpts = np.vstack(kpts).T\n",
    "        kpts = np.round(kpts).astype(np.int)\n",
    "        for kp in kpts:\n",
    "            cv2.circle(img_warp, (kp[1], kp[0]), radius=1, color=(0,255,0))\n",
    "        kpts = np.where(d['image1']['raw']['kpts_map'].squeeze().cpu().numpy())\n",
    "        kpts = np.vstack(kpts).T\n",
    "        kpts = np.round(kpts).astype(np.int)\n",
    "        for kp in kpts:\n",
    "            cv2.circle(img1, (kp[1], kp[0]), radius=1, color=(0,255,0))\n",
    "        kpts = np.where(d['image1']['warp']['kpts_map'].squeeze().cpu().numpy())\n",
    "        kpts = np.vstack(kpts).T\n",
    "        kpts = np.round(kpts).astype(np.int)\n",
    "        for kp in kpts:\n",
    "            cv2.circle(img_warp1, (kp[1], kp[0]), radius=1, color=(0,255,0))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        plt.imshow(img_warp)\n",
    "        plt.show()\n",
    "        plt.imshow(img1)\n",
    "        plt.show()\n",
    "        plt.imshow(img_warp1)\n",
    "        plt.show()\n",
    "        \n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca9a02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('/Users/zhouchang/Desktop/SuperPoint-Pytorch-master/data/self/images/1377155868.png').squeeze().astype(np.int).astype(np.uint8)\n",
    "kpts = np.load('/Users/zhouchang/Desktop/SuperPoint-Pytorch-master/data/self/keypoints/1377155868.npy').astype(np.float32)\n",
    "\n",
    "for kp in kpts:\n",
    "    cv2.circle(img, (int(kp[0]+0.5), int(kp[1]+0.5)), radius=3, color=(0,255,0))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "for kp in kpts:\n",
    "    cv2.circle(img, (int(kp[0]), int(kp[1])), radius=3, color=(0,255,0))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19803a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss test\n",
    "with open('/Users/zhouchang/Documents/GitHub/SuperPoint-Pytorch/config/superpoint_train.yaml','r') as fin:\n",
    "        config = yaml.safe_load(fin)\n",
    "\n",
    "selfdata = SelfDataset(config['data'],True)\n",
    "cdataloader = DataLoader(selfdata,collate_fn=selfdata.batch_collator,batch_size=config['solver']['train_batch_size'],shuffle=True)\n",
    "\n",
    "for i, data in enumerate(cdataloader):\n",
    "    if i>=5:\n",
    "        break\n",
    "    des = torch.rand([config['solver']['train_batch_size'],256,240,320])\n",
    "    des1 = torch.rand([config['solver']['train_batch_size'], 256,240,320])\n",
    "    print(descriptor_loss(config['solver'],data['image']['warp']['kpts'],data['image1']['warp']['kpts'],des,des1,data['pairs'],data['masks'],device='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a0b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
